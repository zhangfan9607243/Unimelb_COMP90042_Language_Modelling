# Language Modelling in Hangman

## Acknowledgement
I would like to extend my sincere gratitude to the Unimelb COMP90042 2023S1 teaching team for providing me with the opportunity to work on this project, as well as for their guidance and feedback on my work.

## Project Introduction

This project implements AI players for the Hangman game using various language models, from simple unigram approaches to advanced n-gram models. The goal is to minimize incorrect guesses by learning character patterns from text corpora.

## Project Tasks

1. Prepare a dataset of words from the NLTK Brown corpus for training and testing the language models.
2. Implement the following language models for the Hangman game, and evaluate their performance in terms of the average number of incorrect guesses:

- Random baseline guesser
- Unigram language model
- Unigram length-conditioned model
- Bigram language model
- Self-defined advanced models (e.g., trigram, combined models)